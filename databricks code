name: CPAD Databricks Deployment - DEV/QA/REL/PROD
on:
  workflow_dispatch:
    inputs:
      organization_or_username:
        description: 'Specify the organization or username to deploy code from'
        required: true
        default: 'smbc-devops'

      repository:
        description: 'Specify the repository to deploy code from'
        required: true
        default: 'SMBC-CCA-MS-Analytics-Environment'

      branch:
        description: 'Specify the branch to deploy code from'
        required: true
        default: 'develop'

      environment:
        description: 'Choose the environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - qa
          - rel
          - prod

env:
  organization_or_username: ${{ github.event.inputs.organization_or_username || 'smbc-devops' }}
  repository: ${{ github.event.inputs.repository || 'SMBC-CCA-MS-Analytics-Environment' }}
  branch: ${{ github.event.inputs.branch || 'develop' }}
  environment: ${{ github.event.inputs.environment || 'dev' }}
  PROJECT_NAME: "CPAD-Analytics"
  PYTHON_VERSION: 3.10

permissions:
  contents: read
  pull-requests: write
  id-token: write

jobs:
  build:
    name: Build Python Packages and Notebooks
    runs-on: ubuntu-latest
    environment: dev

    steps:
      - name: Checkout Repository
        uses: actions/checkout@v4
        with:
          repository: ${{ env.organization_or_username }}/${{ env.repository }}
          ref: ${{ env.branch }}
          token: ${{ secrets.GITHUB_PAT_TOKEN }}

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install wheel setuptools

      - name: Build Python Packages (if applicable)
        run: |
          if [ -f setup.py ]; then
            python setup.py sdist bdist_wheel
            ls -ltr dist
          fi

      - name: Publish Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: ${{ format('{0}_Artifacts', env.PROJECT_NAME) }}
          path: |
            notebooks/
            dist/
            config/

  deploy-dev:
    name: Deploy to Databricks (DEV)
    runs-on: ubuntu-latest
    needs: build
    if: ${{ github.event.inputs.environment == 'dev' }}
    environment: dev

    steps:
      - name: Checkout Repository for Deploy
        uses: actions/checkout@v4
        with:
          repository: ${{ env.organization_or_username }}/${{ env.repository }}
          ref: ${{ env.branch }}
          token: ${{ secrets.GITHUB_PAT_TOKEN }}

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Tools
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli

      - name: Configure Databricks CLI for DEV
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ vars.DEV_DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.DEV_DATABRICKS_TOKEN }}" >> ~/.databrickscfg

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ format('{0}_Artifacts', env.PROJECT_NAME) }}

      - name: Deploy Notebooks to DEV Databricks
        run: |
          # Create directory structure in Databricks
          databricks workspace mkdirs /Repos/dev/${{ env.PROJECT_NAME }}
          
          # Import notebooks organized by layers
          if [ -d "notebooks/bronze" ]; then
            databricks workspace import_dir notebooks/bronze/ /Repos/dev/${{ env.PROJECT_NAME }}/bronze/ -o
          fi
          if [ -d "notebooks/silver" ]; then
            databricks workspace import_dir notebooks/silver/ /Repos/dev/${{ env.PROJECT_NAME }}/silver/ -o
          fi
          if [ -d "notebooks/gold" ]; then
            databricks workspace import_dir notebooks/gold/ /Repos/dev/${{ env.PROJECT_NAME }}/gold/ -o
          fi
          if [ -d "notebooks/common" ]; then
            databricks workspace import_dir notebooks/common/ /Repos/dev/${{ env.PROJECT_NAME }}/common/ -o
          fi

      - name: Upload to DEV Storage Account
        if: ${{ github.event.inputs.environment == 'dev' }}
        env:
          AZURE_STORAGE_ACCOUNT: stccamsduse201
          AZURE_CONTAINER: ccams-dev
        run: |
          # Install Azure CLI if needed for storage operations
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
          # Note: Storage upload would require proper authentication setup

  deploy-qa:
    name: Deploy to Databricks (QA)
    runs-on: ubuntu-latest
    needs: build
    if: ${{ github.event.inputs.environment == 'qa' }}
    environment: qa

    steps:
      - name: Checkout Repository for Deploy
        uses: actions/checkout@v4
        with:
          repository: ${{ env.organization_or_username }}/${{ env.repository }}
          ref: ${{ env.branch }}
          token: ${{ secrets.GITHUB_PAT_TOKEN }}

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Tools
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli

      - name: Configure Databricks CLI for QA
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ vars.QA_DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.QA_DATABRICKS_TOKEN }}" >> ~/.databrickscfg

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ format('{0}_Artifacts', env.PROJECT_NAME) }}

      - name: Deploy Notebooks to QA Databricks
        run: |
          # Create directory structure in Databricks
          databricks workspace mkdirs /Repos/qa/${{ env.PROJECT_NAME }}
          
          # Import notebooks organized by layers
          if [ -d "notebooks/bronze" ]; then
            databricks workspace import_dir notebooks/bronze/ /Repos/qa/${{ env.PROJECT_NAME }}/bronze/ -o
          fi
          if [ -d "notebooks/silver" ]; then
            databricks workspace import_dir notebooks/silver/ /Repos/qa/${{ env.PROJECT_NAME }}/silver/ -o
          fi
          if [ -d "notebooks/gold" ]; then
            databricks workspace import_dir notebooks/gold/ /Repos/qa/${{ env.PROJECT_NAME }}/gold/ -o
          fi
          if [ -d "notebooks/common" ]; then
            databricks workspace import_dir notebooks/common/ /Repos/qa/${{ env.PROJECT_NAME }}/common/ -o
          fi

      - name: Run QA Validation Tests
        run: |
          # Example: Run validation notebooks
          if [ -d "tests" ]; then
            for test_notebook in tests/*.py; do
              echo "Running test: $test_notebook"
              # Submit job for test execution
              databricks jobs run-now --job-id ${{ vars.QA_TEST_JOB_ID }} || echo "Test job submission completed"
            done
          fi

  deploy-rel:
    name: Deploy to Databricks (REL)
    runs-on: ubuntu-latest
    needs: build
    if: ${{ github.event.inputs.environment == 'rel' }}
    environment: rel
    
    steps:
      - name: Checkout Repository for Deploy
        uses: actions/checkout@v4
        with:
          repository: ${{ env.organization_or_username }}/${{ env.repository }}
          ref: ${{ env.branch }}
          token: ${{ secrets.GITHUB_PAT_TOKEN }}

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Tools
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli

      - name: Configure Databricks CLI for REL
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ vars.REL_DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.REL_DATABRICKS_TOKEN }}" >> ~/.databrickscfg

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ format('{0}_Artifacts', env.PROJECT_NAME) }}

      - name: Deploy Notebooks to REL Databricks
        run: |
          # Create directory structure in Databricks
          databricks workspace mkdirs /Repos/rel/${{ env.PROJECT_NAME }}
          
          # Import notebooks organized by layers
          if [ -d "notebooks/bronze" ]; then
            databricks workspace import_dir notebooks/bronze/ /Repos/rel/${{ env.PROJECT_NAME }}/bronze/ -o
          fi
          if [ -d "notebooks/silver" ]; then
            databricks workspace import_dir notebooks/silver/ /Repos/rel/${{ env.PROJECT_NAME }}/silver/ -o
          fi
          if [ -d "notebooks/gold" ]; then
            databricks workspace import_dir notebooks/gold/ /Repos/rel/${{ env.PROJECT_NAME }}/gold/ -o
          fi
          if [ -d "notebooks/common" ]; then
            databricks workspace import_dir notebooks/common/ /Repos/rel/${{ env.PROJECT_NAME }}/common/ -o
          fi

      - name: Sync with TDR (REL Environment)
        run: |
          # REL environment has TDR connectivity
          echo "REL deployment includes TDR connectivity for validation"
          # Add specific TDR sync operations here if needed

  deploy-prod:
    name: Deploy to Databricks (PROD)
    runs-on: ubuntu-latest
    needs: build
    if: ${{ github.event.inputs.environment == 'prod' }}
    environment: prod

    steps:
      - name: Checkout Repository for Deploy
        uses: actions/checkout@v4
        with:
          repository: ${{ env.organization_or_username }}/${{ env.repository }}
          ref: ${{ env.branch }}
          token: ${{ secrets.GITHUB_PAT_TOKEN }}

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install Tools
        run: |
          python -m pip install --upgrade pip
          pip install databricks-cli

      - name: Configure Databricks CLI for PROD
        run: |
          echo "[DEFAULT]" > ~/.databrickscfg
          echo "host = ${{ vars.PROD_DATABRICKS_HOST }}" >> ~/.databrickscfg
          echo "token = ${{ secrets.PROD_DATABRICKS_TOKEN }}" >> ~/.databrickscfg

      - name: Download Artifacts
        uses: actions/download-artifact@v4
        with:
          name: ${{ format('{0}_Artifacts', env.PROJECT_NAME) }}

      - name: Deploy Notebooks to PROD Databricks
        run: |
          # Create directory structure in Databricks
          databricks workspace mkdirs /Repos/prod/${{ env.PROJECT_NAME }}
          
          # Import notebooks organized by layers
          if [ -d "notebooks/bronze" ]; then
            databricks workspace import_dir notebooks/bronze/ /Repos/prod/${{ env.PROJECT_NAME }}/bronze/ -o
          fi
          if [ -d "notebooks/silver" ]; then
            databricks workspace import_dir notebooks/silver/ /Repos/prod/${{ env.PROJECT_NAME }}/silver/ -o
          fi
          if [ -d "notebooks/gold" ]; then
            databricks workspace import_dir notebooks/gold/ /Repos/prod/${{ env.PROJECT_NAME }}/gold/ -o
          fi
          if [ -d "notebooks/common" ]; then
            databricks workspace import_dir notebooks/common/ /Repos/prod/${{ env.PROJECT_NAME }}/common/ -o
          fi

      - name: Schedule Production Jobs
        run: |
          # Schedule the master pipeline that runs at 11:45 AM EST
          echo "Scheduling production jobs for surveillance patterns"
          # The 14 pipelines are bundled into a master pipeline
          # This would create/update job definitions in PROD

      - name: Verify TDR Connectivity
        run: |
          # PROD environment has TDR connectivity
          echo "Verifying TDR connectivity for production surveillance"
          # Add verification steps for TDR integration

  notification:
    name: Send Notification
    runs-on: ubuntu-latest
    needs: [deploy-dev, deploy-qa, deploy-rel, deploy-prod]
    if: always()
    
    steps:
      - name: Send Notification
        run: |
          # Send notification to the appropriate channels
          echo "Deployment completed for ${{ github.event.inputs.environment }} environment"
          # This could integrate with Teams, Slack, or email notifications
          # Based on the project documentation, teams notifications are already in place

Subject: Re: Due Notice on Training Name(s): Harborside NJ US PPM NH Assignment Type: Required Assignment

Dear OES Team,

Thank you for the reminder.

I have completed the Harborside NJ US PPM NH Assignment certification as required. The training has been marked as completed in the Sensei platform.

Please let me know if any further action is needed on my part.

Best regards,
Sandeep Kumar

Yes, thank you very much!
Hi Brent,
Yes, this is exactly what I was looking for. The access package link for the GitHub administrator role looks perfect.
I'll proceed to request this access package through the provided MyAccess link. This will enable me to configure the GitHub Actions CI/CD pipeline for our CPAD Analytics Environment project.
I appreciate your quick response and assistance in pointing me to the right access package.
Thank you again for your help!
Best regards,
Sandeep

**Business Justification:**

Need GitHub administrator access to configure repository settings, secrets, and CI/CD workflows for CPAD Analytics Environment integration with Azure Databricks. This enables automated deployment of compliance surveillance models with proper governance controls required for regulatory requirements.


